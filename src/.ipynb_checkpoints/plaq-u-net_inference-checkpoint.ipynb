{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plaq-u-net: multi-patch consensus U-Net for automated detection and segmentation of the carotid arteries on black blood MRI sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Lavrova, 2022\n",
    "\n",
    "This is a code supporting the corresponding paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "import pydicom\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "import cv2\n",
    "import SimpleITK as sitk\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage import img_as_float\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from scipy.ndimage import zoom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0408 10:59:05.267633 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0408 10:59:05.267633 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0408 10:59:05.267633 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0408 10:59:08.797454 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'                        \n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining model blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 8, dropout = 0.2, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    smooth=1\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    from keras.losses import binary_crossentropy\n",
    "    return 0.5*keras.losses.binary_crossentropy(y_true,y_pred)+0.5*dice_loss(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models compilation + loading weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0408 10:59:10.701388 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0408 10:59:10.709390 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0408 10:59:10.713390 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4185: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "W0408 10:59:10.752390 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0408 10:59:10.811392 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0408 10:59:10.902394 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0408 10:59:10.916394 33308 deprecation.py:506] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0408 10:59:11.578971 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0408 10:59:12.368487 33308 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "img (InputLayer)                (None, 64, 64, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 16)   160         img[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64, 64, 16)   64          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 64, 64, 16)   0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 16)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 16)   0           max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 32, 32, 32)   4640        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 32, 32, 32)   128         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 32, 32, 32)   0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 16, 16, 32)   0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 16, 16, 32)   0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 16, 16, 64)   18496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 16, 16, 64)   256         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 16, 16, 64)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 8, 8, 64)     0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 64)     0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 8, 8, 128)    73856       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 8, 8, 128)    512         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 8, 8, 128)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 4, 4, 128)    0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4, 4, 128)    0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 256)    295168      dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 4, 4, 256)    1024        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 4, 4, 256)    0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 8, 8, 128)    295040      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 8, 8, 256)    0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 8, 8, 256)    0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 8, 8, 128)    295040      dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 8, 8, 128)    512         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 8, 8, 128)    0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 16, 16, 64)   73792       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 16, 16, 128)  0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 16, 16, 128)  0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 16, 16, 64)   73792       dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 64)   256         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 32, 32, 32)   18464       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 32, 64)   0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 32, 32, 64)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 32, 32, 32)   18464       dropout_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 32, 32, 32)   128         conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 32, 32, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 64, 64, 16)   4624        activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 64, 64, 32)   0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 64, 64, 32)   0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 64, 64, 16)   4624        dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 64, 64, 16)   64          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 64, 64, 16)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 64, 64, 1)    17          activation_18[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,179,121\n",
      "Trainable params: 1,177,649\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "im_height = 64\n",
    "im_width = 64\n",
    "\n",
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "\n",
    "model_simple = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_simple.compile(optimizer=Adam(), loss=dice_loss, metrics=['accuracy', dice_coef])\n",
    "model.load_weights('../res/plaq-u-net_simple.h5')\n",
    "\n",
    "model_aug = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_aug.compile(optimizer=Adam(), loss=dice_loss, metrics=['accuracy', dice_coef])\n",
    "model.load_weights('../res/plaq-u-net_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patching and consensus map calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect4multipatches(img, model):\n",
    "    \n",
    "    steps = int((img.shape[0]-64)/4)+1\n",
    "    \n",
    "    M = np.empty((img.shape[0], img.shape[1], steps*steps))\n",
    "    M[:] = np.NaN\n",
    "    img_patch = np.zeros((steps*steps, 64, 64, 1))\n",
    "    c = 0\n",
    "\n",
    "    for i in range (0, steps):\n",
    "        for j in range (0, steps):\n",
    "            \n",
    "            img_crop = img[4*i:4*i+64, 4*j:4*j+64]\n",
    "            img_patch[c, ..., 0] = img_crop.copy()\n",
    "            c += 1\n",
    "            \n",
    "    img_patch_pred = model.predict(img_patch, verbose=0)\n",
    "    \n",
    "    c = 0\n",
    "    for i in range (0, steps):\n",
    "        for j in range (0, steps):\n",
    "            M[4*i:4*i+64, 4*j:4*j+64, c] = img_patch_pred[c, ..., 0]\n",
    "            c += 1\n",
    "            \n",
    "    M_concord = np.nanmean(M, axis = 2)\n",
    "    \n",
    "    del M\n",
    "            \n",
    "    return M_concord"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CA probability maps calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some data loading and pre-processing functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading DICOM to array from the file path\n",
    "def path2array(dcm_path):\n",
    "    arr_dcm = pydicom.read_file(dcm_path, force = True)\n",
    "    arr_dcm.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "    arr = arr_dcm.pixel_array\n",
    "    return arr\n",
    "\n",
    "# N4 bias field correction\n",
    "def correctBiasField(img_input):\n",
    "    \n",
    "    corrected = False\n",
    "    img_output = np.zeros(img_input.shape)\n",
    "\n",
    "    while not corrected:\n",
    "\n",
    "        try:\n",
    "            corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "            inputImage = sitk.GetImageFromArray(img_input)\n",
    "            inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n",
    "            output = corrector.Execute(inputImage)\n",
    "            img_output = sitk.GetArrayFromImage(output)\n",
    "            corrected = True\n",
    "        except:\n",
    "            print ('BFC failed')\n",
    "\n",
    "    return img_output\n",
    "\n",
    "# zooming images to defined voxel size and array shape (with cropping/padding)\n",
    "# from: https://stackoverflow.com/questions/37119071/scipy-rotate-and-zoom-an-image-without-changing-its-dimensions\n",
    "def clipped_zoom(img, zoom_factor, **kwargs):\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
    "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
    "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
    "    zoom_tuple = (zoom_factor,) * 2 + (1,) * (img.ndim - 2)\n",
    "\n",
    "    # Zooming out\n",
    "    if zoom_factor < 1:\n",
    "\n",
    "        # Bounding box of the zoomed-out image within the output array\n",
    "        zh = int(np.round(h * zoom_factor))\n",
    "        zw = int(np.round(w * zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        # Zero-padding\n",
    "        out = np.zeros_like(img)\n",
    "        out[top:top+zh, left:left+zw] = zoom(img, zoom_tuple, **kwargs)\n",
    "\n",
    "    # Zooming in\n",
    "    elif zoom_factor > 1:\n",
    "\n",
    "        # Bounding box of the zoomed-in region within the input array\n",
    "        zh = int(np.round(h / zoom_factor))\n",
    "        zw = int(np.round(w / zoom_factor))\n",
    "        top = (h - zh) // 2\n",
    "        left = (w - zw) // 2\n",
    "\n",
    "        out = zoom(img[top:top+zh, left:left+zw], zoom_tuple, **kwargs)\n",
    "\n",
    "        # `out` might still be slightly larger than `img` due to rounding, so\n",
    "        # trim off any extra pixels at the edges\n",
    "        trim_top = ((out.shape[0] - h) // 2)\n",
    "        trim_left = ((out.shape[1] - w) // 2)\n",
    "        out = out[trim_top:trim_top+h, trim_left:trim_left+w]\n",
    "\n",
    "    # If zoom_factor == 1, just return the input array\n",
    "    else:\n",
    "        out = img\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting patient names from the test set (from training script):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_test = ['AMC012', 'AMC006', 'MUMC094', 'MUMC027', 'MUMC079', 'MUMC052', 'MUMC127', 'MUMC071', 'MUMC038',\n",
    "                  'MUMC093', 'MUMC107', 'MUMC022', 'MUMC114', 'MUMC115', 'MUMC069', 'MUMC130', 'MUMC036', 'MUMC007', \n",
    "                  'MUMC059', 'MUMC080', 'UMCU036', 'UMCU025', 'UMCU008', 'UMCU034']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating CA probability maps and saving to the results folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12769/12769 [==============================] - 10s 770us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 381us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 380us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 407us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 405us/step\n",
      "12769/12769 [==============================] - 5s 405us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 403us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 375us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 385us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 370us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 404us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 404us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-040944293150>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0mimg_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcorrectBiasField\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_norm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m         \u001b[0mvessels_pred_multi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetect4multipatches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m         \u001b[1;31m#vessels_pred_multi_th = vessels_pred_multi > 0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#vessels_pred_multi_th_morph = morphology.remove_small_objects(vessels_pred_multi_th, 100, connectivity=3)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-b80333a51f3a>\u001b[0m in \u001b[0;36mdetect4multipatches\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mM\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mM\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mimg_patch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ds_dir = 'C:/Users/E.Lavrova/Documents/GitHub/plaq-u-net/data/'\n",
    "results_dir = 'I:/parisk_validation/validation_masks/test_set/'\n",
    "\n",
    "for sub_name in sub_names_test:\n",
    "    \n",
    "    os.mkdir(results_dir+sub_name)\n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name)\n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "        img_norm = np.copy((img - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "\n",
    "        img_test = correctBiasField(img_norm[8:-8,8:-8])\n",
    "        \n",
    "        vessels_pred_multi = detect4multipatches(img_test)\n",
    "        \n",
    "        np.save(results_dir + sub_name + '/' + sub_img_name.split(os.sep)[2][-10:-4] + '.npy', vessels_pred_multi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 418us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 418us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 404us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 403us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 418us/step\n",
      "12769/12769 [==============================] - 5s 418us/step\n",
      "12769/12769 [==============================] - 5s 420us/step\n",
      "12769/12769 [==============================] - 5s 418us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 408us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 420us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 407us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 404us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 419us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 403us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 400us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 420us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 417us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 407us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 408us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 403us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 415us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 410us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 407us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 414us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 409us/step\n",
      "12769/12769 [==============================] - 5s 403us/step\n",
      "12769/12769 [==============================] - 5s 412us/step\n",
      "12769/12769 [==============================] - 5s 400us/step\n",
      "12769/12769 [==============================] - 5s 408us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 406us/step\n",
      "12769/12769 [==============================] - 5s 413us/step\n",
      "12769/12769 [==============================] - 5s 406us/step\n",
      "12769/12769 [==============================] - 5s 411us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 381us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 403us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 416us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 401us/step\n",
      "12769/12769 [==============================] - 5s 382us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 385us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 364us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 380us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 385us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12769/12769 [==============================] - 4s 338us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 378us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 4s 342us/step\n",
      "12769/12769 [==============================] - 5s 359us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 4s 332us/step\n",
      "12769/12769 [==============================] - 4s 344us/step\n",
      "12769/12769 [==============================] - 5s 375us/step\n",
      "12769/12769 [==============================] - 4s 346us/step\n",
      "12769/12769 [==============================] - 4s 322us/step\n",
      "12769/12769 [==============================] - 5s 367us/step\n",
      "12769/12769 [==============================] - 5s 382us/step\n",
      "12769/12769 [==============================] - 4s 332us/step\n",
      "12769/12769 [==============================] - 5s 353us/step\n",
      "12769/12769 [==============================] - 5s 375us/step\n",
      "12769/12769 [==============================] - 5s 370us/step\n",
      "12769/12769 [==============================] - 5s 370us/step\n",
      "12769/12769 [==============================] - 5s 363us/step\n",
      "12769/12769 [==============================] - 5s 363us/step\n",
      "12769/12769 [==============================] - 4s 333us/step\n",
      "12769/12769 [==============================] - 5s 363us/step\n",
      "12769/12769 [==============================] - 5s 371us/step\n",
      "12769/12769 [==============================] - 4s 346us/step\n",
      "12769/12769 [==============================] - 5s 372us/step\n",
      "12769/12769 [==============================] - 4s 334us/step\n",
      "12769/12769 [==============================] - 5s 382us/step\n",
      "12769/12769 [==============================] - 5s 369us/step\n",
      "12769/12769 [==============================] - 5s 374us/step\n",
      "12769/12769 [==============================] - 5s 381us/step\n",
      "12769/12769 [==============================] - 5s 359us/step\n",
      "12769/12769 [==============================] - 5s 379us/step\n",
      "12769/12769 [==============================] - 5s 361us/step\n",
      "12769/12769 [==============================] - 5s 352us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 363us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 382us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 386us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 400us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 400us/step\n",
      "12769/12769 [==============================] - 5s 382us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 400us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 380us/step\n",
      "12769/12769 [==============================] - 5s 381us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 382us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 378us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 395us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 384us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 385us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 385us/step\n",
      "BFC failed\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 398us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 400us/step\n",
      "12769/12769 [==============================] - 5s 387us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 392us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 393us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 399us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 383us/step\n",
      "12769/12769 [==============================] - 5s 397us/step\n",
      "12769/12769 [==============================] - 5s 390us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 388us/step\n",
      "12769/12769 [==============================] - 5s 394us/step\n",
      "12769/12769 [==============================] - 5s 391us/step\n",
      "12769/12769 [==============================] - 5s 396us/step\n",
      "12769/12769 [==============================] - 5s 389us/step\n",
      "12769/12769 [==============================] - 5s 380us/step\n"
     ]
    }
   ],
   "source": [
    "ds_dir = 'I:/parisk_validation/validation_sets/EMC/'\n",
    "results_dir = 'I:/parisk_validation/validation_masks/EMC/'\n",
    "\n",
    "for folder_name in os.listdir(ds_dir):\n",
    "    \n",
    "    sub_name = folder_name[:6]\n",
    "    \n",
    "    os.mkdir(results_dir+sub_name)\n",
    "    sub_img_names = glob.glob(ds_dir+sub_name+'*/T1W_*.dcm')\n",
    "    \n",
    "    for sub_img_name in sub_img_names:\n",
    "        \n",
    "        img = path2array(sub_img_name);\n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "        img_norm = np.copy((img - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "        img_norm_bfc = correctBiasField(img_norm)\n",
    "\n",
    "        img_test = cv2.resize(img_norm_bfc.copy(), dsize=(512, 512), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        vessels_pred_multi = detect4multipatches(img_test)\n",
    "        vessels_pred_multi_res = cv2.resize(vessels_pred_multi.copy(), dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
    "        \n",
    "        np.save(results_dir + sub_name + '/' + sub_img_name.split(os.sep)[2][-17:-11] + '.npy', vessels_pred_multi_res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
