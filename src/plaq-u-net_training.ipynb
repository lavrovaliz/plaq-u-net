{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plaq-u-net: multi-patch consensus U-Net for automated detection and segmentation of the carotid arteries on black blood MRI sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "E. Lavrova, 2022  \n",
    "  \n",
    "This is a code supporting the corresponding paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Packages import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "import pydicom\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "from skimage.io import imread, imshow, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "from skimage import morphology\n",
    "from skimage.filters import threshold_otsu, threshold_local\n",
    "\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from itertools import chain\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input, BatchNormalization, Activation, Dense, Dropout\n",
    "from keras.layers.core import Lambda, RepeatVector, Reshape\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D, GlobalMaxPool2D\n",
    "from keras.layers.merge import concatenate, add\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "import SimpleITK as sitk\n",
    "\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0416 00:17:07.485317 31444 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0416 00:17:07.488317 31444 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0416 00:17:07.489317 31444 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "W0416 00:17:11.123268 31444 module_wrapper.py:139] From C:\\ProgramData\\Anaconda3\\envs\\segway\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/job:localhost/replica:0/task:0/device:GPU:0',\n",
       " '/job:localhost/replica:0/task:0/device:GPU:1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '2,3'                        \n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "K.tensorflow_backend._get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting image/contour names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = glob.glob('../data/*/T1W_*.dcm')\n",
    "contours = glob.glob('../data/*/MASSExport/*.dcm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of image/contour files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2806, 2821)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images), len(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting patients with contours presented:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_names_list = []\n",
    "for image in images:\n",
    "    sub_name = image.split(os.sep)[1].split('_')[0]\n",
    "    con_names = glob.glob(os.path.join(os.path.split(image)[0],'MASSExport')+os.sep+'*'+ image.split(os.sep)[2][-10:-4]+'*.dcm')\n",
    "    if len(con_names)>0:\n",
    "        sub_names_list.append(sub_name)\n",
    "        \n",
    "sub_names = np.unique(sub_names_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting subs into centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 115 25 34\n"
     ]
    }
   ],
   "source": [
    "sub_names_amc = []\n",
    "sub_names_mumc = []\n",
    "sub_names_umcu = []\n",
    "sub_names_emc = []\n",
    "\n",
    "for sub_name in sub_names:\n",
    "    if 'AMC' in sub_name:\n",
    "        sub_names_amc.append(sub_name)\n",
    "    if 'MUMC' in sub_name:\n",
    "        sub_names_mumc.append(sub_name)\n",
    "    if 'UMCU' in sub_name:\n",
    "        sub_names_umcu.append(sub_name)\n",
    "    if 'EMC' in sub_name:\n",
    "        sub_names_emc.append(sub_name)\n",
    "        \n",
    "print (len(sub_names_amc), len(sub_names_mumc), len(sub_names_umcu), len(sub_names_emc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data split for training, validation, and testing stratified per center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 80 17\n",
      "2 17 4\n",
      "2 18 4\n",
      "34\n"
     ]
    }
   ],
   "source": [
    "sub_names_amc_train, sub_names_amc_valid_test = train_test_split(sub_names_amc, test_size=0.3, \n",
    "                                                                 random_state=2022, shuffle=True)\n",
    "sub_names_amc_valid, sub_names_amc_test = train_test_split(sub_names_amc_valid_test, test_size=0.5, \n",
    "                                                           random_state=2022, shuffle=True)\n",
    "\n",
    "sub_names_mumc_train, sub_names_mumc_valid_test = train_test_split(sub_names_mumc, test_size=0.3, \n",
    "                                                                 random_state=2022, shuffle=True)\n",
    "sub_names_mumc_valid, sub_names_mumc_test = train_test_split(sub_names_mumc_valid_test, test_size=0.5, \n",
    "                                                           random_state=2022, shuffle=True)\n",
    "\n",
    "sub_names_umcu_train, sub_names_umcu_valid_test = train_test_split(sub_names_umcu, test_size=0.3, \n",
    "                                                                 random_state=2022, shuffle=True)\n",
    "sub_names_umcu_valid, sub_names_umcu_test = train_test_split(sub_names_umcu_valid_test, test_size=0.5, \n",
    "                                                           random_state=2022, shuffle=True)\n",
    "\n",
    "sub_names_train = sub_names_amc_train + sub_names_mumc_train + sub_names_umcu_train\n",
    "sub_names_valid = sub_names_amc_valid + sub_names_mumc_valid + sub_names_umcu_valid\n",
    "sub_names_test = sub_names_amc_test + sub_names_mumc_test + sub_names_umcu_test\n",
    "\n",
    "print (len(sub_names_amc_train), len(sub_names_mumc_train), len(sub_names_umcu_train))\n",
    "print (len(sub_names_amc_valid), len(sub_names_mumc_valid), len(sub_names_umcu_valid))\n",
    "print (len(sub_names_amc_test), len(sub_names_mumc_test), len(sub_names_umcu_test))\n",
    "print (len(sub_names_emc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of patients in training, validation, and testing subsets per center:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|DS | Total  | Train    | Valid   | Test   | Ext test |\n",
    "|---:|:-------------|:-----------|:------|:------|:-----|\n",
    "| AMC | 13  | 9 | 2   | 2     |0|\n",
    "| MUMC | 115  | 80    | 17   | 18     |0|\n",
    "| UMCU | 25  | 17    | 4   | 4     |0|  \n",
    "| EMC | 34|0|0|0|34|\n",
    "| Total | 187  | 106    | 23   | 24     |34|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting .dcm files for every subset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1589 345 360\n"
     ]
    }
   ],
   "source": [
    "img_names_train = []\n",
    "img_names_valid = []\n",
    "img_names_test = []\n",
    "\n",
    "for sub_name_train in sub_names_train:\n",
    "    img_names_train.extend(glob.glob('Z:/Lisa/PARISK/PARISK-XNAT/plaque_converted_unempty slices/'+sub_name_train+'*/T1W_*.dcm'))\n",
    "\n",
    "for sub_name_valid in sub_names_valid:\n",
    "    img_names_valid.extend(glob.glob('Z:/Lisa/PARISK/PARISK-XNAT/plaque_converted_unempty slices/'+sub_name_valid+'*/T1W_*.dcm'))\n",
    "    \n",
    "for sub_name_test in sub_names_test:\n",
    "    img_names_test.extend(glob.glob('Z:/Lisa/PARISK/PARISK-XNAT/plaque_converted_unempty slices/'+sub_name_test+'*/T1W_*.dcm'))\n",
    "    \n",
    "print (len(img_names_train), len(img_names_valid), len(img_names_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patch settings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_side = 64\n",
    "im_width = im_side\n",
    "im_height = im_side\n",
    "border = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training data aggregation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty arrays for training data\n",
    "\n",
    "X_train = np.zeros((len(img_names_train), im_side, im_side, 1), dtype = np.uint8)\n",
    "y_train = np.zeros((len(img_names_train), im_side, im_side, 1), dtype = np.uint8)\n",
    "\n",
    "X_valid = np.zeros((len(img_names_valid), im_side, im_side, 1), dtype = np.uint8)\n",
    "y_valid = np.zeros((len(img_names_valid), im_side, im_side, 1), dtype = np.uint8)\n",
    "\n",
    "X_test = np.zeros((len(img_names_test), im_side, im_side, 1), dtype = np.uint8)\n",
    "y_test = np.zeros((len(img_names_test), im_side, im_side, 1), dtype = np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read DICOM from path to array\n",
    "\n",
    "def path2array(dcm_path):\n",
    "    arr_dcm = pydicom.read_file(dcm_path, force = True)\n",
    "    arr_dcm.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "    arr = arr_dcm.pixel_array\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slice normalization and training patch crop\n",
    "\n",
    "def norm_crop(img_arr, con_arr, im_side, rs):\n",
    "    \n",
    "    random.seed(rs)\n",
    "    \n",
    "    img_min = np.min(img_arr) \n",
    "    img_max = np.max(img_arr) \n",
    "    \n",
    "    img_norm = np.copy((img_arr - img_min)/(img_max - img_min)*255).astype(np.uint8)\n",
    "\n",
    "    con_xmin = np.min(np.where(con_arr > 0)[0])\n",
    "    con_xmax = np.max(np.where(con_arr > 0)[0])\n",
    "    con_ymin = np.min(np.where(con_arr > 0)[1])\n",
    "    con_ymax = np.max(np.where(con_arr > 0)[1])\n",
    "        \n",
    "    side_x = con_xmax - con_xmin\n",
    "    side_y = con_ymax - con_ymin\n",
    "\n",
    "    crop_xmin = max(0, con_xmin-random.randint(2, max(2, im_side-side_x)))\n",
    "    crop_ymin = max(0, con_ymin-random.randint(2, max(2, im_side-side_y)))\n",
    "        \n",
    "    crop_xmax = crop_xmin + im_side\n",
    "    crop_ymax = crop_ymin + im_side\n",
    "\n",
    "    crop = [crop_xmin, crop_xmax, crop_ymin, crop_ymax]\n",
    "\n",
    "    img_norm_crop = np.copy(img_norm[crop[0]:crop[1], crop[2]:crop[3]])\n",
    "    con_crop = np.copy(con_arr[crop[0]:crop[1], crop[2]:crop[3]])\n",
    "\n",
    "    return img_norm_crop, con_crop>0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image pre-processing: N4 bias field correction\n",
    "\n",
    "def correctBiasField(img_input):\n",
    "    \n",
    "    corrected = False\n",
    "    img_output = np.zeros(img_input.shape)\n",
    "\n",
    "    while not corrected:\n",
    "\n",
    "        try:\n",
    "            corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "            inputImage = sitk.GetImageFromArray(img_input)\n",
    "            inputImage = sitk.Cast(inputImage, sitk.sitkFloat32)\n",
    "            output = corrector.Execute(inputImage)\n",
    "            img_output = sitk.GetArrayFromImage(output)\n",
    "            corrected = True\n",
    "        except:\n",
    "            print ('BFC failed')\n",
    "\n",
    "    return img_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregation of the training patches from the corresponding DICOM paths\n",
    "\n",
    "def paths2dataarray(paths_list, X_array, y_array, im_side):\n",
    "    \n",
    "    i = 0\n",
    "\n",
    "    for impth in paths_list:\n",
    "\n",
    "        img = path2array(impth)\n",
    "        con_name = glob.glob(os.path.join(os.path.split(impth)[0],'MASSExport')+os.sep+'*'+ impth.split(os.sep)[2][-10:-4]+'*.dcm')[0]\n",
    "        con = path2array(con_name)\n",
    "        \n",
    "        #img_bfc = correctBiasField(img)\n",
    "        \n",
    "        img_min = np.min(img)\n",
    "        img_max = np.max(img)\n",
    "\n",
    "        if (np.sum(con)>0)&((img_max - img_min)>0):\n",
    "\n",
    "            img_prep, con_prep = norm_crop(img, con, im_side, i)\n",
    "\n",
    "            X_array[i, ..., 0] = img_prep\n",
    "            y_array[i, ..., 0] = con_prep\n",
    "\n",
    "            i+=1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# aggregation of the training, validation, and testing patches\n",
    "\n",
    "paths2dataarray(img_names_train, X_train, y_train, 64)\n",
    "paths2dataarray(img_names_valid, X_valid, y_valid, 64)\n",
    "paths2dataarray(img_names_test, X_test, y_test, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualization of the training patches\n",
    "\n",
    "for i in range (0, 10):\n",
    "    plt.imshow(X_train[i, ..., 0], cmap = 'bone')\n",
    "    plt.imshow(y_train[i, ..., 0], alpha = 0.3)\n",
    "    plt.axis('Off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining transformations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomSizedCrop(min_max_height=(48, 64), height=64, width=64, p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.Blur(p=0.5),\n",
    "    A.GaussNoise(p=0.5),\n",
    "    A.RandomBrightnessContrast(brightness_limit=0.25, contrast_limit=0.25, p=0.5),\n",
    "    A.RandomGamma(p=0.5)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generation of the augmented patches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_augms random transformations of the images X and masks y\n",
    "\n",
    "def augment_ds(X, y, n_augms):\n",
    "    \n",
    "    counter = 0\n",
    "    dim = y[0, ..., 0].shape\n",
    "    n_samples = y.shape[0]\n",
    "    \n",
    "    X_aug = np.zeros((int(n_samples*n_augms), dim[0], dim[1], 1), dtype = np.uint8)\n",
    "    y_aug = np.zeros((int(n_samples*n_augms), dim[0], dim[1], 1), dtype = np.uint8)\n",
    "    \n",
    "    for smpl in range (0, n_samples):\n",
    "        for augm in range (0, n_augms):\n",
    "            \n",
    "            random.seed(counter)\n",
    "            augmented = transform(image=X[smpl, ..., 0], mask=y[smpl, ..., 0])\n",
    "            X_aug[counter, ..., 0] = augmented['image']\n",
    "            y_aug[counter, ..., 0] = augmented['mask']\n",
    "            counter += 1\n",
    "            \n",
    "    return X_aug, y_aug    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing augmented data into arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_aug, y_train_aug = augment_ds(X_train, y_train, 10)\n",
    "X_valid_aug, y_valid_aug = augment_ds(X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the transformed images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 5\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.subplot(121)\n",
    "plt.imshow(X_train[n_sample//10, ..., 0])\n",
    "plt.contour(y_train[n_sample//10, ..., 0], colors='r')\n",
    "plt.subplot(122)\n",
    "plt.imshow(X_train_aug[n_sample, ..., 0])\n",
    "plt.contour(y_train_aug[n_sample, ..., 0], colors='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. U-Net construction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_block(input_tensor, n_filters, kernel_size = 3, batchnorm = True):\n",
    "    \"\"\"Function to add 2 convolutional layers with the parameters passed to it\"\"\"\n",
    "    # first layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # second layer\n",
    "    x = Conv2D(filters = n_filters, kernel_size = (kernel_size, kernel_size),\\\n",
    "              kernel_initializer = 'he_normal', padding = 'same')(input_tensor)\n",
    "    if batchnorm:\n",
    "        x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def get_unet(input_img, n_filters = 8, dropout = 0.2, batchnorm = True):\n",
    "    \"\"\"Function to define the UNET Model\"\"\"\n",
    "    # Contracting Path\n",
    "    c1 = conv2d_block(input_img, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "    p1 = Dropout(dropout)(p1)\n",
    "\n",
    "    c2 = conv2d_block(p1, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "    p2 = Dropout(dropout)(p2)\n",
    "\n",
    "    c3 = conv2d_block(p2, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p3 = MaxPooling2D((2, 2))(c3)\n",
    "    p3 = Dropout(dropout)(p3)\n",
    "\n",
    "    c4 = conv2d_block(p3, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "    p4 = MaxPooling2D((2, 2))(c4)\n",
    "    p4 = Dropout(dropout)(p4)\n",
    "\n",
    "    c5 = conv2d_block(p4, n_filters = n_filters * 16, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    # Expansive Path\n",
    "    u6 = Conv2DTranspose(n_filters * 8, (3, 3), strides = (2, 2), padding = 'same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    u6 = Dropout(dropout)(u6)\n",
    "    c6 = conv2d_block(u6, n_filters * 8, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u7 = Conv2DTranspose(n_filters * 4, (3, 3), strides = (2, 2), padding = 'same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    u7 = Dropout(dropout)(u7)\n",
    "    c7 = conv2d_block(u7, n_filters * 4, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u8 = Conv2DTranspose(n_filters * 2, (3, 3), strides = (2, 2), padding = 'same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    u8 = Dropout(dropout)(u8)\n",
    "    c8 = conv2d_block(u8, n_filters * 2, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    u9 = Conv2DTranspose(n_filters * 1, (3, 3), strides = (2, 2), padding = 'same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    u9 = Dropout(dropout)(u9)\n",
    "    c9 = conv2d_block(u9, n_filters * 1, kernel_size = 3, batchnorm = batchnorm)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
    "    model = Model(inputs=[input_img], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_true, y_pred):\n",
    "    from keras import backend as K\n",
    "    smooth=1\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coef(y_true, y_pred)\n",
    "\n",
    "def custom_loss(y_true, y_pred):\n",
    "    from keras.losses import binary_crossentropy\n",
    "    return 0.5*keras.losses.binary_crossentropy(y_true,y_pred)+0.5*dice_loss(y_true,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model compilation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input((im_height, im_width, 1), name='img')\n",
    "\n",
    "model_simple = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_simple.compile(optimizer=Adam(), loss=custom_loss, metrics=['accuracy', dice_coef])\n",
    "model_simple.summary()\n",
    "\n",
    "model_aug = get_unet(input_img, n_filters=16, dropout=0.05, batchnorm=True)\n",
    "model_aug.compile(optimizer=Adam(), loss=custom_loss, metrics=['accuracy', dice_coef])\n",
    "model_aug.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_simple = [\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('../res/plaq-u-net_simple.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]\n",
    "\n",
    "callbacks_aug = [\n",
    "    ReduceLROnPlateau(factor=0.1, patience=3, min_lr=0.00001, verbose=1),\n",
    "    ModelCheckpoint('../res/plaq-u-net_aug.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model training with and without augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Models training (with and w/o augmentation):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model (w/o data augmentation)\n",
    "\n",
    "results_simple = model_simple.fit(X_train, y_train,\n",
    "                                  batch_size=32, epochs=100, \n",
    "                                  callbacks=callbacks_simple, \n",
    "                                  validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data augmentation\n",
    "\n",
    "results_aug = model_aug.fit(X_train_aug, y_train_aug,\n",
    "                            batch_size=32, epochs=100, \n",
    "                            callbacks=callbacks_aug, \n",
    "                            validation_data=(X_valid_aug, y_valid_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning curves visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve (simple model)\")\n",
    "plt.plot(results_simple.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results_simple.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results_simple.history[\"val_loss\"]), np.min(results_simple.history[\"val_loss\"]), \n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented model\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.title(\"Learning curve (augmented model)\")\n",
    "plt.plot(results_aug.history[\"loss\"], label=\"loss\")\n",
    "plt.plot(results_aug.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot( np.argmin(results_aug.history[\"val_loss\"]), np.min(results_aug.history[\"val_loss\"]), \n",
    "         marker=\"x\", color=\"r\", label=\"best model\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Models performance on patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple.load_weights('../res/plaq-u-net_simple.h5')\n",
    "model_aug.load_weights('../res/plaq-u-net_aug.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating on the PATCHES of the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model\n",
    "\n",
    "model_simple.evaluate(X_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented model:\n",
    "\n",
    "model_aug.evaluate(X_valid, y_valid, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation on the PATCHES of the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple model\n",
    "\n",
    "model_simple.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augmented model\n",
    "\n",
    "model_aug.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions for the test set (+ thresholding):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_test_simple = model_simple.predict(X_test, verbose=1)\n",
    "preds_test_simple_t = (preds_test_simple > 0.5).astype(np.uint8)\n",
    "\n",
    "preds_test_aug = model_aug.predict(X_test, verbose=1)\n",
    "preds_test_aug_t = (preds_test_aug > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = 90\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(X_test[ix, ..., 0], cmap='viridis')\n",
    "ax[0].contour(y_test[ix].squeeze(), colors='r', levels=[0.5], linewidths=5)\n",
    "ax[0].set_title('True')\n",
    "ax[0].grid(False)\n",
    "\n",
    "ax[1].imshow(X_test[ix, ..., 0], cmap='viridis')\n",
    "ax[1].contour(preds_test_simple[ix].squeeze(), colors='r', levels=[0.5], linewidths=5)\n",
    "ax[1].set_title('Predicted (simple model)')\n",
    "ax[1].grid(False)\n",
    "\n",
    "ax[2].imshow(X_test[ix, ..., 0], cmap='viridis')\n",
    "ax[2].contour(preds_test_aug[ix].squeeze(), colors='r', levels=[0.5], linewidths=5)\n",
    "ax[2].set_title('Predicted (augmented model)')\n",
    "ax[2].grid(False)\n",
    "\n",
    "ax[3].imshow(y_test[ix].squeeze(), vmin=0, vmax=2)\n",
    "ax[3].contour(preds_test_simple[ix].squeeze(), colors='r', levels=[0.5], linewidths=5)\n",
    "ax[3].contour(preds_test_aug[ix].squeeze(), colors='orange', levels=[0.5], linewidths=5)\n",
    "ax[3].set_title('Predicted segmentation')\n",
    "ax[3].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
